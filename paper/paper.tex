\documentclass[runningheads]{llncs}
\usepackage{graphicx}

\newenvironment{nscenter}
 {\parskip=0pt\par\nopagebreak\centering}
 {\par\noindent\ignorespacesafterend}

\begin{document}
\makeatletter
\renewcommand\section{\@startsection{section}{1}{\z@}%
                       {-10\p@}%
                       {8\p@ }%
                       {\normalfont\large\bfseries\boldmath
                        \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
\renewcommand\subsection{\@startsection{subsection}{2}{\z@}%
                       {-9\p@ }%
                       {7\p@ }%
                       {\normalfont\normalsize\bfseries\boldmath
                        \rightskip=\z@ \@plus 8em\pretolerance=10000 }}
\renewcommand\subsubsection{\@startsection{subsubsection}{3}{\z@}%
                       {-5\p@ }%
                       {-2em }%
                       {\normalfont\normalsize\bfseries\boldmath}}
\makeatother

\setlength{\textfloatsep}{0pt plus 0pt minus 0pt}
\setlength{\intextsep}{0pt plus 0pt minus 0pt}
 \setlength{\parskip}{0pt plus 0pt minus 0pt}

\title{Generative LLM oversampling for the class imbalance problem in hate speech detection}
\author{Nicolas Antonio Cloutier\inst{1} \and Nathalie Japkowicz\inst{2}}
\authorrunning{Cloutier \and Japkowicz}
\titlerunning{Generative LLM oversampling for the class imbalance problem}

\institute{Jackson-Reed High School, Washington, D.C., USA\\\email{nicocloutier1@gmail.com} \and American University, Washington, D.C., USA\\\email{japkowicz@american.edu}}

\maketitle 

\begin{abstract}
Online hate speech has become increasingly prevalent with the rise of social media. As such, methods for automatically detecting and classifying hate speech have become the subject of much research. A common challenge in this and other domains is the class imbalance problem, where one class in a dataset is far more common than another. We propose the use of a generative large language model (LLM), specifically OpenAI's GPT-2, as a method of oversampling text data in order to account for this imbalance, comparing it to other resampling methods on three tasks: binary classification of tweets as antisemitic or not, multi-class classification of antisemitic tweets into subtypes, and a combination of the two. We find that generative LLM resampling does not produce better results for binary classification than other resampling methods, but does improve performance on the other two tasks.
\end{abstract}

\section{Introduction}
%P1: Introduce the issue of hate speech online
In recent years, hate speech has become increasingly mainstream and common within social media sites \cite{siegel}. This rise has not only caused online spaces to become less hospitable, but has also had several offline effects. On top of having severe psychological effects on the recipient \cite{siegel}, online hate speech also played a role in disseminating extremist anti-Rohingya voices leading to violence in Myanmar \cite{green}, and has provided motivation for several perpetrators of offline violent hate crimes \cite{siegel}. These events have motivated responses from numerous parties, including the social media sites themselves, that are increasingly looking to stop the spread of these messages \cite{ullmann}, and governmental bodies, that are seeking to regulate or prevent the spread of hate speech \cite{banks}. At the same time as hate speech has been becoming more common, social media sites have been generating more and more content, with popular social media site Twitter generating an average of 500 million tweets per day in 2019 \cite{pereira}.

%P2: Introduce the need for automated methods of hate speech detection
With these developments and the large amount of content on social media sites, these sites have been increasingly looking to automatic detection methods for hate speech \cite{ullmann}. These methods use Machine Learning (ML) to automatically detect and classify hateful speech, removing some of the work done by moderators, whose primary job is to respond reactively to user reports of hate speech \cite{ullmann}. Chandra et al. \cite{chandra} used a combination of image and text processing and classification algorithms to classify images and text on social media sites Twitter and Gab as antisemitic or not \cite{chandra}. In this paper, we seek a lower cost method that uses only the text component of their dataset to further analyze the presence of hate speech on Twitter and investigate new algorithms for classification.\footnote{Our dataset contains less samples than that of \cite{chandra} because Twitter removed some of the hateful posts before we collected the data.}

%P3: Introduce the imbalanced data issue
One difficulty with this dataset is that it is imbalanced, meaning one classification is far more common in the dataset than another. Imbalanced data can negatively impact the performance of ML classification algorithms \cite{sun}, affecting numerous domains that use ML classification. Many ML algorithms are inadequately prepared to handle the class imbalance problem \cite{sun}, leading many to look to other solutions, including resampling methods, that in some way change the training data by adding or removing samples in order to allay the effects of the class imbalance problem \cite{japkowicz}.

%P4: Wrap up the research question and context
With this in mind, along with the recent advances in generative LLMs, we ask whether such methods can allay the class imbalance problem in text data better than traditional approaches, and to what extent that may improve hate speech detection on social media.

\section{Previous work}
%P1: mention big paper that you use
Antisemitism detection, as well as hate speech detection generally, has been the subject of much research. Martins et al. \cite{martins} used ML models to analyze and classify antisemitism in posts on social media sites Gab and 4chan, and González-Pizarro and Zanettou \cite{gonzalez} used large language models (LLMs) to do the same. Chandra et al. \cite{chandra} introduced a new dataset of labeled antisemitic posts, including text and images. These posts were labeled not only for whether or not they are antisemitic, but also their type of antisemitism, with the researchers grouping antisemitic posts into political, economic, religious, and racial antisemitism, and trained models to classify both antisemitic status and type of antisemitism. This Twitter dataset is imbalanced, with the non-antisemitic class far outnumbering the antisemitic class, and with political and racial antisemitism being more common than religious and economic antisemitism.

%P2: introduce previous work on class imbalance problem
Imbalance is a common issue in ML classification problems. The class imbalance problem can severely negatively affect model predictive power, with the less common class (termed the ``minority class'') often being misclassified due to its low prevalence in the dataset relative to the larger class (the ``majority class'') \cite{abdelrahman}. This problem has affected fields as distinct as medicine, fraudulent call detection, and risk management \cite{sun}. Due to the severity with which this problem can limit model performance and its widespread nature, being seen in numerous distinct fields, it has become a focus of researchers as an area of improvement \cite{abdelrahman}, with numerous techniques being created to allay the effects of the problem.

%P3: focus on resampling methods
One such group of techniques is resampling, altering the training data by adding new samples or taking existing samples away in order to improve model performance. Generally, there are two types of resampling: oversampling, which describes the process of adding samples to a dataset, and undersampling, which describes the process of removing existing samples from a dataset \cite{shelke}. Resampling techniques can improve the performance of ML models when trained on imbalanced data \cite{lee} \cite{khushi}.

%P4: talk about generative models used in vision, tabular data
One method for oversampling is the use of generative models, including generative adversarial networks (GANs) and autoencoders to generate synthetic data. These methods seek to match the distribution of the original dataset and create synthetic samples in accordance with that distribution \cite{hao}, with the goal of creating synthetic examples for model training that match the original distribution closely. They have achieved success in their applications, but primarily in computer vision and tabular data \cite{hao} \cite{engelmann} \cite{bellinger} \cite{dai}. Applications of these generative models to natural language processing (NLP) do occur \cite{phung}, but they are generally less common than applications to other areas. NLP tends to use more traditional statistical methods for oversampling such as SMOTE and random oversampling \cite{wijaya} \cite{glazkova}.

%P5: talk about LLMs and their applications, find whether there is research done with LLMs on class imbalance
While these advances in resampling have been occurring, similar advances have been made in generative LLMs, such as the GPT series of models from OpenAI, which have the ability to generate human-like text \cite{floridi} and have been applied to fields such as patent claim generation \cite{hsiang} and healthcare education \cite{sallam}. These LLMs have been investigated as a method for oversampling text data to account for the class imbalance problem, with relatively consistent success over not using resampling \cite{edwards} \cite{usuga} \cite{shaikh}. That being said, these studies do not compare the method with other, simpler or more traditional resampling methods. Drummond \& Holte \cite{drummond} argue that complex methods of resampling are difficult to justify without marked improvements in performance over simpler methods. This provides motivation, now that the method has shown success in accounting for the class imbalance, for investigating how it compares to existing methods of resampling and under which circumstances it improves relative to those methods.

\section{Methodology}
%P1: talk about the different tasks
The purpose of our paper is to study the effects of various types of resampling on hate speech detection and classification tasks. Our models were trained on three different tasks. The first was a simple binary classification task, where the models attempted to classify the text of a tweet as either antisemitic or not antisemitic. The second was the 4-class type classification, where the dataset was limited to only antisemitic samples, that was then grouped into four classes: political, economic, religious, and racial antisemitism. Finally, the models were trained on a 5-class type classification task, where the dataset included both antisemitic and non-antisemitic samples, and the model attempted to classify the samples into one of the four groups of antisemitism or classify them as not antisemitic, creating five classes total. Every model was trained and tested separately for all three tasks.

%P2: talk about the different types of models trained
In order to best represent a variety of ML architectures, different algorithms and methods of text representation were used. For algorithms, we trained classifiers utilizing the Naïve Bayes, Extreme Gradient Boosting, Decision Tree, and Support Vector Machine algorithms. We also used three methods of representing text: term frequency-inverse document frequency (TF-IDF), raw frequency, and Bag of Words (BoW).\footnote{We initially included a BERT-based representation method, but the models trained with this method produced results no better than chance.} Each model was trained with each method of text representation, creating a total of twelve models that were trained for each task. In order to reduce the dimensionality of the dataset, representations for training and testing data were limited to words that had a frequency score of at least 0.5\%, meaning that the word had to have a frequency of at least 0.5\% of the original, full length of the text in order to be considered by the models.

The dataset is imbalanced. Figure 1 shows the distribution of different classes in the dataset. The first and third charts are for the entire dataset, and the second, containing classifications on types of antisemitism, only contains samples that are antisemitic.\\

\begin{nscenter}
\includegraphics[width=.3\textwidth]{binary\_pie.pdf}
\includegraphics[width=.3\textwidth]{type\_pie.pdf}
\includegraphics[width=.3\textwidth]{type5\_pie.pdf}

{\bf Figure 1.} Classification distributions
\end{nscenter}

%P3: talk about the resampling methods used
Several methods of resampling were used to reduce the impact of the class imbalance, which were chosen to represent a variety of resampling techniques and algorithms. One set of models was trained with no resampling, with additional sets being trained using random undersampling \cite{shelke}, random oversampling \cite{shelke}, SMOTE with Tomek Links\footnote{SMOTE with Tomek links was selected over only SMOTE in order to represent combined oversampling and undersampling methods, as there are two other methods already (AdaSyn and random oversampling) that are pure oversampling.} \cite{fernandez}, AdaSyn \cite{he}, and a final set being trained on the augmented dataset generated using the LLM. GPT-2 was used to generate the samples because it is easily available and callable programmatically with the HuggingFace API, unlike more recently released GPT models. The augmented dataset was created by generating 20 samples from each sample in the original dataset, creating a dataset that was larger, but had the same percentages of class imbalance. These models then used random undersampling on this larger dataset to account for this. This was done in order to avoid having to regenerate samples for each model, due to the large number of models being trained.

%P4: talk about the augmented dataset specifically and testing
In regards to testing, each model was tested using 10-fold cross-validation on the original dataset. It was ensured that no samples generated from oversampling methods were used during testing, and additionally that, when testing the augmented model, if a sample that was used to generate more samples appeared in the testing split, the samples generated with it would not appear in the training split. This ensures that the models were not unfairly advantaged, and that each was tested on a large amount of genuine, unseen data.

%P5: talk about evaluation (mean recall) and methods used (cochran, etc)
For model evaluation, the two main metrics used were the macro-averages of the recall and precision scores across each of the classes the model had to classify for each task. This was used in lieu of accuracy in order to account for the class imbalance in the data. Once the models were evaluated, their answers to the testing samples were converted to a binary matrix with each column representing a model and each row representing a sample. We then used the Cochran's Q-test, an extension of McNemar's test appropriate for the case of comparing multiple algorithms on a single domain, to test for significant difference in the models, then the Dunn test for post-hoc analysis.\footnote{See \cite{boukouvalas}} When testing the resampling methods against each other, the data were turned into another matrix with each column representing a resampling method and each row representing a model trained with that method, with the value in the cell being the mean recall or precision of that model. A Friedman's $\chi^2$ test was then performed with a post-hoc Nemenyi test to analyze the results.

{\parskip=0pt
\section{Results}
Overall, the models trained on the LLM-augmented data showed no improvement on the binary task, but they did show improvement on the 5-class classification and especially the 4-class classification tasks. Tables 1 \& 2 contain information for the binary classification task with each resampling method, as well as the best-performing model performance and mean model performance for each resampling method out of the twelve combinations of each algorithm (Naïve Bayes, SVM, Decision Tree, and Extreme Gradient Boosting) and representation method (BoW, TF-IDF, and frequency), with ``performance'' meaning the mean recall or precision score the model achieved. The best model was the best performing model of all of the models trained with that particular resampling method, not taking into account the performance on other resampling methods. The data used to create Table 1 received a Friedman $\chi^2$ test \emph{p}-value of $2.2 \times 10^{-2}$, while Table 2 received a \emph{p}-value of $1.6 \times 10^{-3}$, allowing a rejection of the null hypothesis with $\alpha=0.05$. After each table, an array is provided with the results of the post-hoc Nemenyi test on the resampling methods, with \emph{p}-values displayed in the array. A higher \emph{p}-value and lighter color means we cannot reject the null hypothesis, while a lower \emph{p}-value and darker color means we can. In these arrays, ``RU'' stands for random undersampling, ``ST'' stands for SMOTE with Tomek links, ``RO'' stands for random oversampling, ``AD'' stands for AdaSyn, ``NO'' stands for no resampling method, and ``LA'' stands for LLM-augmented.}
\begin{nscenter}
{\bf Table 1.} Binary task resampling method recall\\

\begin{tabular}{|l|l|l|}
\hline
Resampling Method & Best score (\% over none) & Mean score (\% over none) \\\hline
None (NO) & 0.667 (0\%) & 0.613 (0\%) \\\hline
Random Undersampling (RU) & 0.689 (3.3\%) & {\bf 0.638 (4.1\%)} \\\hline
SMOTE-Tomek (ST) & 0.668 (0.1\%) & 0.614 (0.2\%) \\\hline
Random Oversampling (RO) & {\bf 0.690 (3.4\%)} & 0.623 (1.6\%) \\\hline
AdaSyn (AD) & 0.661 (-0.9\%) & 0.608 (0.8\%) \\\hline
LLM-Augmented (LA) & 0.679 (1.8\%) & 0.617 (0.7\%) \\\hline
\end{tabular}

\includegraphics[scale=0.6]{binary-recall.pdf}\\
{\bf Figure 2.} Binary recall Nemenyi test results\\
\vspace{\baselineskip}
{\bf Table 2.} Binary task resampling method precision\\

\begin{tabular}{|l|l|l|}
\hline
Resampling Method & Best score (\% over none) & Mean score (\% over none) \\\hline
None (NO) & {\bf 0.734 (0\%)} & {\bf 0.644 (0\%)} \\\hline
Random Undersampling (RU) & 0.666 (-9.3\%) & 0.621 (-3.6\%) \\\hline
SMOTE-Tomek (ST) & 0.670 (-8.7\%) & 0.612 (-5.0\%) \\\hline
Random Oversampling (RO) & 0.674 (-8.2\%) & 0.617 (-4.2\%) \\\hline
AdaSyn (AD) & 0.646 (-12.0\%) & 0.600 (-6.8\%) \\\hline
LLM-Augmented (LA) & 0.668 (-9.0\%) & 0.613 (-4.8\%) \\\hline
\end{tabular}

\includegraphics[scale=0.6]{binary-precision.pdf}\\
{\bf Figure 3.} Binary precision Nemenyi test results
\end{nscenter}
In the binary task, the LLM-augmented models show no performance improvement over the other models. Generally, the resampling methods tend to do better than the models with no resampling on recall, but have worse precision performance, with this pattern being sustained by the models trained on LLM-augmented data.

The results of the 5-class classification task are shown below. The data used to create Table 3 received a Friedman $\chi^2$ test \emph{p}-value of $3.4 \times 10^{-6}$, while Table 4 received a \emph{p}-value of $4.1 \times 10^{-2}$.
\begin{nscenter}
{\bf Table 3.} 5-class task resampling method recall\\

\begin{tabular}{|l|l|l|}
\hline
Resampling Method & Best score (\% above none) & Mean score (\% above none) \\\hline
None (NO) & 0.312 (0\%) & 0.265 (0\%) \\\hline
Random Undersampling (RU) & 0.321 (2.9\%) & 0.265 (0\%) \\\hline
SMOTE-Tomek (ST) & 0.289 (-7.4\%) & 0.271 (2.3\%) \\\hline
Random Oversampling (RO) & 0.369 (18.3\%) & 0.298 (12.5\%) \\\hline
AdaSyn (AD) & 0.316 (1.3\%) & 0.251 (-5.3\%) \\\hline
LLM-Augmented (LA) & {\bf 0.402 (28.8\%)} & {\bf 0.347 (30.9\%)} \\\hline
\end{tabular}

\includegraphics[scale=0.6]{5type-recall.pdf}\\
{\bf Figure 4.} 5-class recall Nemenyi test results\\
\vspace{\baselineskip}
{\bf Table 4.} 5-class task resampling method precision\\

\begin{tabular}{|l|l|l|}
\hline
Resampling Method & Best score (\% above none) & Mean score (\% above none) \\\hline
None (NO) & {\bf 0.524 (0\%)} & {\bf 0.325 (0\%)} \\\hline
Random Undersampling (RU) & 0.274 (-47.7\%) & 0.249 (-23.4\%) \\\hline
SMOTE-Tomek (ST) & 0.295 (-43.7\%) & 0.264 (-18.8\%) \\\hline
Random Oversampling (RO) & 0.319 (-39.1\%) & 0.271 (-16.6\%) \\\hline
AdaSyn (AD) & 0.436 (-16.8\%) & 0.286 (-12.0\%) \\\hline
LLM-Augmented (LA) & 0.302 (-42.4\%) & 0.270 (-16.9\%) \\\hline
\end{tabular}

\includegraphics[scale=0.6]{5type-precision.pdf}\\
{\bf Figure 5.} 5-class precision Nemenyi test results
\end{nscenter}
The results on the 5-type task begin to show the benefits of LLM augmentation. The pattern of no resampling outperforming resampling on precision while the inverse happens on recall remains, but now LLM augmentation improves over no resampling by a far wider margin than any other resampling method, while retaining similar levels of drops in precision to other methods. Now, its gain in mean recall is larger than its loss in mean precision, which is not the case for any other resampling method in the 5-class task, and is only true for random undersampling in the binary task.

The results of the 4-class classification task are shown below. The data used to create Table 5 received a Friedman $\chi^2$ test \emph{p}-value of $5.3 \times 10^{-4}$, while Table 6 received a \emph{p}-value of $4.2 \times 10^{-5}$.
\begin{nscenter}
{\bf Table 5.} 4-class task resampling method recall\\

\begin{tabular}{|l|l|l|}
\hline
Resampling Method & Best score (\% above none) & Mean score (\% above none) \\\hline
None (NO) & 0.337 (0\%) & 0.328 (0\%) \\\hline
Random Undersampling (RU) & 0.414 (22.8\%) & 0.339 (3.4\%) \\\hline
SMOTE-Tomek (ST) & 0.420 (24.6\%) & 0.366 (11.6\%) \\\hline
Random Oversampling (RO) & 0.400 (18.7\%) & 0.358 (9.1\%) \\\hline
AdaSyn (AD) & 0.471 (39.8\%) & 0.322 (-1.8\%) \\\hline
LLM-Augmented (LA) & {\bf 0.509 (51.0\%)} & {\bf 0.433 (32.0\%)} \\\hline
\end{tabular}

\includegraphics[scale=0.6]{4type-recall.pdf}\\
{\bf Figure 6.} 4-class recall Nemenyi test results\\
\vspace{\baselineskip}
{\bf Table 6.} 4-class task resampling method precision\\

\begin{tabular}{|l|l|l|}
\hline
Resampling Method & Best score (\% above none) & Mean score (\% above none) \\\hline
None (NO) & 0.452 (0\%) & 0.372 (0\%) \\\hline
Random Undersampling (RU) & 0.361 (-17.9\%) & 0.323 (-13.2\%) \\\hline
SMOTE-Tomek (ST) & 0.381 (-15.7\%) & 0.347 (-6.7\%) \\\hline
Random Oversampling (RO) & 0.374 (-17.3\%) & 0.351 (-5.6\%) \\\hline
AdaSyn (AD) & 0.378 (-16.4\%) & 0.344 (-7.5\%) \\\hline
LLM-Augmented (LA) & {\bf 0.504 (11.5\%)} & {\bf 0.409 (9.9\%)} \\\hline
\end{tabular}

\includegraphics[scale=0.6]{4type-precision.pdf}\\
{\bf Figure 5.} 4-class precision Nemenyi test results
\end{nscenter}
Now, the pattern of gains on recall and losses on precision continue for all methods except LLM augmentation. LLM-augmented models not only increase the recall by a greater margin than any other method, but also increase the precision of the model on the 4-class task. This makes it the only resampling method in any of the three tasks to receive a higher precision score either on the best model or on mean score than no resampling, on top of widening the margin by which it beats no resampling compared to the 5-class task.

One initial possible explanation for the high performance of the models with LLM-augmented data relative to other models on the 5-class and especially 4-class tasks is that the LLM augmentation provides performance improvements with only one particular class that other resampling methods did poorly on, artificially raising the mean recall even though there was only one class affected significantly. Looking further at the data, however, while some classes were more affected than others, overall, the models trained on LLM-augmented data show improvements in multiple classes. On the 4-type classification task, Tables 7 \& 8 show the mean recall and precision of each method on each particular class, respectively.
\begin{nscenter}
{\bf Table 7.} 4-class task class-wise resampling method recall\\

\begin{tabular}{|l|l|l|l|l|}
\hline
Resampling Method & Political & Economic & Religious & Racial \\\hline
None (NO) & {\bf 0.618} & 0.106 & 0.203 & 0.283 \\\hline
Random Undersampling (RU) & 0.379 & {\bf 0.240} & 0.434 & 0.200  \\\hline
SMOTE-Tomek (ST) & 0.506 & 0.135 & 0.465 & 0.245 \\\hline
Random Oversampling (RO) & 0.487 & 0.163 & 0.442 & 0.230 \\\hline
AdaSyn (AD) & 0.574 & 0.135 & 0.223 & 0.258 \\\hline
LLM-Augmented (LA) & 0.492 & 0.231 & {\bf 0.471} & {\bf 0.405} \\\hline
\end{tabular}

{\bf Table 8.} 4-class task class-wise resampling method precision\\

\begin{tabular}{|l|l|l|l|l|}
\hline
Resampling Method & Political & Economic & Religious & Racial \\\hline
None (NO) & 0.598 & 0.029 & 0.254 & 0.390 \\\hline
Random Undersampling (RU) & 0.601 & 0.024 & 0.205 & 0.362 \\\hline
SMOTE-Tomek (ST) & 0.653 & 0.018 & 0.234 & 0.378 \\\hline
Random Oversampling (RO) & {\bf 0.661} & 0.015 & 0.227 & 0.392 \\\hline
AdaSyn (AD) & 0.602 & 0.017 & 0.243 & 0.390 \\\hline
LLM-Augmented (LA) & 0.577 &{\bf  0.111} & {\bf 0.367} & {\bf 0.431} \\\hline
\end{tabular}
\end{nscenter}
In precision and recall, the model is outperformed in political antisemitism (the largest class), and in recall it is slightly outperformed by random undersampling in economic antisemitism, but it outperforms the other models in religious and racial antisemitism on recall and in all classes other than political in precision.

\section{Discussion}
The most striking result is the difference in relative performance of the resampling methods between the three tasks. The binary task sees small improvements in recall with overall larger losses in precision, the 5-class task sees large losses in precision with large gains in recall, particularly by the LLM, and the 4-class task sees large gains in recall and precision for the LLM, with other methods having smaller recall gains and performing worse than no resampling on precision. This can primarily be explained through two factors: the degree of imbalance of the data and the degree of appropriateness of an oversampling technique to the task at hand.

First, the degree of imbalance can affect the relative performance of resampling methods. The binary task saw the least benefit from resampling methods, as its losses in precision generally outweighed its gains in recall. This can be explained by the fact that the binary task had relatively large amounts of data for both classes, making resampling less useful compared to other tasks, hence why the observed improvement in recall is less than that of other tasks. For the 5-class task, on the other hand, the classes are imbalanced to a very high degree, with sample sizes ranging from 8 to 877. In order to make these classes equal in size, drastic measures must be taken, either by removing large portions of the dataset or adding a quantity of synthetic or duplicated samples that outnumber the original size of that class within the dataset. This can, in the case of undersampling, remove critical pieces of information that could help the model \cite{marques} \cite{kraiem}, and, in the case of oversampling, introduce excessive amounts of synthetic data or make the dataset prone to overfitting \cite{marques} \cite{kraiem}. This could explain the large decreases in precision in this task. On the 4-class task, the imbalance is far more even, with sample sizes ranging from 8 to 170, certainly still a large difference, but a far cry from the 5-class task. This could explain why the losses in precision for the 4-class task are not as high as those in the 5-class task.

This factor, however, does not explain all of the difference. Why, for example, do the models trained on LLM-generated data outperform other models by such a wide margin in the 4-class task, not only in recall but also precision? Here, it is necessary to look at the methods themselves and the algorithms they use. The generative LLM, being trained on large amounts of text data, has likely been trained partially on samples similar in topic, purpose, or register to the ones present in the dataset. Its familiarity with this type of text allows it to generate more appropriate synthetic samples than those generated purely geometrically by such algorithms as SMOTE and AdaSyn, while avoiding the overfitting that can plague random oversampling as a result of simply duplicating data \cite{marques} \cite{kraiem}.

These two factors, when considered together, can explain a large portion of the observed differences in performance of the resampling methods across the three tasks. The binary case saw very little improvement from any method because the degree of imbalance was not very high, and there was ample data present from both classes. The 5-class task saw the best performance from the models trained on LLM-generated data because this method is the best-suited to the task, but the very large class imbalance negatively affected precision to a high degree. The 4-class task also saw the best performance from these models for the same reason, but the lower degree of class imbalance made the losses in precision lower, making all methods, but especially the generative LLM due to its high appropriateness to the task, perform better on average precision on this task than the previous one.

\section{Conclusions and Future Work}
In this paper, we propose a method of oversampling for text data involving the use of generative LLMs to generate text samples and account for the class imbalance problem. We apply this method to an imbalanced antisemitism classification dataset on three tasks, one binary classification and two multiclass classification. We find that this method does not provide benefits over other methods on the binary classification task, but provides improvements over other methods in the 5-class and especially 4-class tasks. Our findings suggest that generative LLM oversampling, like other resampling methods, does not provide large benefits when there is plentiful data for both classes, and will not perform as well when there is a very large degree of imbalance, but has merit over other methods in certain tasks. We hypothesize that this is because the generative LLMs, by basing the generation on existing text knowledge rather than geometry like other synthetic oversampling methods, are more appropriate to the task of oversampling text data.

For future work in the area, we believe it is important to verify the results and conclusions we have reached. This could be achieved through testing the methods on a wide variety of tasks, with different types of text data (different registers, topics, etc.), different numbers of classes, and different degrees of imbalance. These studies could help test our analyses of the results and pinpoint the situations where generative LLM resampling is most appropriate.

\begin{thebibliography}{33}
\bibitem{abdelrahman}
Abd Elrahman, S. M., Abraham, A: A review of class imbalance problem. Journal of Network and Innovative Computing \textbf{1}, 332--340 (2013)

\bibitem{banks}
Banks, J.: Regulating hate speech online. International Review of Law, Computers and Technology \textbf{24}(3), 233--239 (2010)

\bibitem{bellinger}
Bellinger, C., Japkowicz, N., Drummond, C.: Synthetic oversampling for advanced radioactive threat detection. IEEE Conference on Machine Learning and Applications 2015

\bibitem{chandra}
Chandra, M., Pailla, D., Bhatia, H., Sanchawala, A., Gupta, M., Shrivastava, M., Kumaraguru, P.: ``Subverting the Jewtocracy'': Online Antisemitism Detection Using Multimodal Deep Learning. ACM Web Science Conference 2021, 148--157

\bibitem{dai}
Dai, W., Ng, K., Severson, K., Huan, W., Anderson, F., Stultz, C.: Generative oversampling with a contrastive variational autoencoder. IEEE International Conference on Data Mining 2019, 101--109

\bibitem{drummond}
Drummond, C., Holte, R. C.: C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling. Workshop on Learning from Imbalanced Datasets 2003

\bibitem{edwards}
Edwards, A., Ushio, A., Camacho-Collados, J., De Ribaupierre, H., Preece, A.: Guiding Generative Language Models for Data Augmentation in Few-Shot Text Classification. \emph{arXiv preprint arXiv:2111.09064}, (2021)

\bibitem{engelmann}
Engelmann, J., Lessmann, S.: Conditional Wasserstein GAN-based oversampling of tabular data for imbalanced learning. Expert Systems with Applications \textbf{174}, (2021)

\bibitem{fernandez}
Fernández, A., García, S., Herrera, F., Chawla, N. V.: SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary. Journal of Artificial Intelligence Research \textbf{61}, 863--905 (2018)

\bibitem{floridi}
Floridi, L., Chiriatti, M.: GPT-3: Its nature, scope, limits, and consequences. Minds and Machines \textbf{30}, 681--694 (2020)

\bibitem{glazkova}
Glazkova, A.: A comparison of synthetic oversampling methods for multi-class text classification. \emph{arXiv preprint arXiv:2008.04636t}, (2020)

\bibitem{gonzalez}
González-Pizarro, F., Zannettou, S.: Understanding and detecting hateful content using contrastive learning. \emph{arXiv preprint arXiv:2201.08387}, (2022)

\bibitem{green}
Green, P., MacManus, T., De la Cour Venning, A.: Countdown to Annihilation: Genocide in Myanmar. International State of Crime Initiative, London (2015)

\bibitem{hao}
Hao, J., Wang, C., Zhang, H., Yang, G.: Annealing genetic GAN for minority oversampling. \emph{arXiv preprint}, (2020)

\bibitem{he}
He, H., Bai, Y., Garcia, E. A., Li, S.: ADASYN: Adaptive Synthetic Approach for Imbalanced Learning. IEEE International Joint Conference on Neural Networks 2008, 1322--1328

\bibitem{japkowicz}
Japkowicz, N., Shaju, S.: The class imbalance problem: A systematic study. Intelligent Data Analysis \textbf{6}(5), 429--449 (2002)

\bibitem{boukouvalas}
Japkowicz, N., Boukouvalas, Z., Shah, M.: Machine Learning Evaluation (in preparation)

\bibitem{khushi}
Khushi, M., Shaukat, K., Alam, T. M., Hammed, I. A., Uddin, S., Luo, S., Yang, X., Consuelo Reyes, M.: A Comparative Performance Analysis of Data Resampling Methods on Imbalance Medical Data. IEEE Access \textbf{9}, 109960--109975 (2021)

\bibitem{kraiem}
Kraiem, M. S., Sánchez-Hernández F., Moreno-García M. N.: Selecting the suitable resampling strategy for imbalanced data classification regarding dataset properties. an approach based on association models. Applied Sciences \textbf{11}(18), 8546 (2021)

\bibitem{hsiang} %the main author is also named lee, this is the second author
Lee, J. S., Hsiang, J.: Patent Claim Generation by Fine-Tuning OpenAI GPT-2. World Patent Information \textbf{62}, (2020)

\bibitem{lee}
Lee, P. H.: Resampling methods improve the predictive power of modeling in class-imbalanced datasets. International Journal of Environmental Research and Public Health \textbf{11}(9), 9776--9789.

\bibitem{marques}
Marqués, A. I., García, V., Salvador Sánchez, J.: On the suitability of resampling techniques for the class imbalance problem for credit scoring. Journal of the Operational Research Society \textbf{64}(7), 1060--1070 (2013)

\bibitem{martins}
Martins, R., Gomes, M., Almeida, J. J., Novais, P., Henriques, P.: Hate speech classification in social media using emotional analysis. Brazilian Conference on Intelligent Systems 2018, 61--66

\bibitem{pereira}
Pereira-Kohatsu, J. C., Quijano-Sánchez, L., Liberatore, F., Camacho-Collados, M.: Detecting and Monitoring Hate Speech in Twitter. Sensors \textbf{19}(21), 4654--4691 (2019)

\bibitem{phung}
Phung, N. M., Mimura, M.: Evaluation of a cGAN Model and Random Seed Oversampling on Imbalanced JavaScript Datasets. Journal of Information Processing \textbf{30}, 591--600 (2022)

\bibitem{sallam}
Sallam, M.: The utility of ChatGPT as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. \emph{medRxiv preprint}, (2023)

\bibitem{shaikh}
Shaikh, S., Daudpota, S. M., Imran, A. I., Kastrati, Z.: Towards Improved Classification Accuracy on Highly Imbalanced Text Dataset Using Deep Neural Language Models. Applied Sciences \textbf{11}(2), 869 (2021)

\bibitem{shelke}
Shelke, M. S., Deshmukh, P. R., Shandilya, V. K.: A review on imbalanced data handling using undersampling and oversampling technique. International Journal of Recent Trends in Engineering Research \textbf{3}(4), 444--449 (2017)

\bibitem{siegel}
Siegel, A.: Online Hate Speech. Social media and democracy: The state of the field, prospects for reform, 56--88 (2020)

\bibitem{sun}
Sun, Y., Wong, A., Kamel, M.: Classification of Imbalanced Data: A Review. International Journal of Pattern Recognition and Artificial Intelligence \textbf{23}(4), 687--719 (2009)

\bibitem{ullmann}
Ullmann, S., Tomalin, M.: Quarantining online hate speech: technical and ethical perspectives. Ethics and Information Technology \textbf{22}, 69--80 (2020)

\bibitem{usuga}
Usuga-Cadavid, J. P., Grabot, B., Lamouri, S., Fortin, A.: Artificial Data Generation with Language Models for Imbalanced Classification in Maintenance. International Workshop on Service Orientation in Holonic and Multi-Agent Manufacturing 2021, 57--68

\bibitem{wijaya}
Wijaya, I. D., Putrada, A. G., Oktaria, D.: Overcoming Data Imbalance Problems in Sexual Harassment Classification with SMOTE. International Journal on Information and Communication Technology \textbf{8}(1), 20--29 (2022)

\end{thebibliography}
\end{document}
