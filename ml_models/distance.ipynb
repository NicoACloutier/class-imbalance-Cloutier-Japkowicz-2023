{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e928a4a-acfd-4628-a03b-4e5ae8a5905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, collections, typing, math, warnings\n",
    "import imblearn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e4a987-d2bb-46b2-936e-44bef420e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efabc1e6-3038-4209-b215-97983f5e1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "resampling_methods = {'SMOTE': imblearn.over_sampling.SMOTE, \n",
    "                      'RandomOver': imblearn.over_sampling.RandomOverSampler,\n",
    "                      #'ADASYN': imblearn.over_sampling.ADASYN,\n",
    "                      'aug': None}\n",
    "K_FOLDS = 5 #folds for k-fold x-validation\n",
    "INPUT_NAME = 'text' #name of input column in df\n",
    "THRESHOLD_PCT = 0.5 #minimum percent of text that must be taken up by a particular word\n",
    "OUTPUT_NAMES = ['Binary', '4-type', '5-type']\n",
    "AUG_NAME = '../data/augmented_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5e81dc-d6b1-483b-a256-737e38673c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word representations\n",
    "def bow(text: str, wordlist: list[str]) -> list[int]:\n",
    "    '''Represent text with bag of words.'''\n",
    "    return [int(word in text) for word in wordlist]\n",
    "\n",
    "def freq(text: str, wordlist: list[str]) -> list[float]:\n",
    "    '''Represent text with frequencies.'''\n",
    "    text = text.split()\n",
    "    counter = collections.Counter(text)\n",
    "    length = len(text)\n",
    "    return [value_or_zero(word, counter)/length for word in wordlist]\n",
    "\n",
    "def tfidf(text: str, word_dict: dict[str, float]) -> list[float]:\n",
    "    '''Represent text with TF-IDF'''\n",
    "    text = text.split()\n",
    "    counter = collections.Counter(text)\n",
    "    length = len(text)\n",
    "    frequencies = [value_or_zero(word, counter)/length for word in word_dict]\n",
    "    return [word_dict[word] * frequencies[i] for (i, word) in enumerate(word_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c50b00-b8da-44b7-9262-6fe377758c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data formatting and wrangling functions\n",
    "def remove_below_threshold(array: np.ndarray, value_array: np.ndarray, threshold: float) -> np.ndarray:\n",
    "    '''Remove all elements from an array where same index in another array is greater than a particular threshold.'''\n",
    "    return np.array([value for i, value in enumerate(array) if value_array[i] <= threshold])\n",
    "    \n",
    "def get_all_text(df: pd.DataFrame) -> str:\n",
    "    '''Get a string with all text from a pandas DataFrame.'''\n",
    "    return ' '.join(list(df[INPUT_NAME]))\n",
    "\n",
    "def remove_uncommon_words(wordlist: list[str], text_counter: dict[str, int]) -> list[str]:\n",
    "    '''Remove words that are uncommon, below a certain threshold.'''\n",
    "    return [word for word in wordlist if text_counter[word]*100/len(wordlist) >= THRESHOLD_PCT]\n",
    "\n",
    "def combine_answers(df: pd.DataFrame, names: list[str]) -> pd.DataFrame:\n",
    "    '''Combine the answers to get the 5-type class'''\n",
    "    df = df.fillna(0)\n",
    "    columns = list(df.columns.values)\n",
    "    data_type, classification = columns.index(names[0]), columns.index(names[1])\n",
    "    df[OUTPUT_NAMES[2]] = df.apply(lambda x: x[data_type] + x[classification], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_wordlist(df: pd.DataFrame) -> tuple[list[str], dict[str, int]]:\n",
    "    '''Get the wordlist for a dataframe.'''\n",
    "    all_text_split = get_all_text(df).split()\n",
    "    all_text_counter = collections.Counter(all_text_split)\n",
    "    return remove_uncommon_words(list(set(all_text_split)), all_text_counter), all_text_counter\n",
    "\n",
    "def get_worddict(df: pd.DataFrame, frequency_counter: dict[str, int], \n",
    "                 wordlist: list[str]) -> dict[str, float]:\n",
    "    '''Get the word dict for a dataframe, for the TF-IDF encoding.'''\n",
    "    all_text_split = get_all_text(df).split()\n",
    "    all_text_counter = collections.Counter(all_text_split)\n",
    "    word_dict = dict()\n",
    "    for word in wordlist:\n",
    "        value = math.log(len(wordlist)/all_text_counter[word])\n",
    "        word_dict[word] = value\n",
    "    return word_dict\n",
    "\n",
    "def resample(inputs: np.ndarray, outputs: np.ndarray, resampling_method: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "    '''Resample a dataset with a resampling method.'''\n",
    "    try:\n",
    "        if resampling_method not in ['aug', 'none']:\n",
    "            inputs, outputs = methods[resampling_method]().fit_resample(inputs, outputs)\n",
    "    except ValueError: #sometimes it doesn't generate any new samples, which gives value error. In that case, return original.\n",
    "        pass\n",
    "    return inputs, outputs\n",
    "\n",
    "def value_or_zero(key: str, temp_dict: dict[str, int]) -> int:\n",
    "    '''Return value in a dictionary or zero if key not in dictionary.'''\n",
    "    return 0 if key not in temp_dict else temp_dict[key]\n",
    "\n",
    "def delete_punctuation(input_string: str) -> str:\n",
    "    '''Delete the punctuation from a string.'''\n",
    "    return ''.join(char for char in input_string if char not in string.punctuation)\n",
    "\n",
    "def find_distances(original: np.ndarray, resampled: np.ndarray) -> np.ndarray:\n",
    "    '''Find the distances between two numpy ndarrays.'''\n",
    "    return np.linalg.norm(original - resampled, axis=1)\n",
    "\n",
    "def represent_text(df: pd.DataFrame, rep_func: typing.Callable,\n",
    "                  rep_list: typing.Union[list[str], dict[str, float]]) -> np.ndarray:\n",
    "    '''Represent text in a dataframe with a given representation method.'''\n",
    "    representation = df[INPUT_NAME].apply(lambda x: rep_func(x, rep_list)).to_numpy()\n",
    "    return np.array([np.array(x) for x in representation]) #it doesn't do this automatically for some reason\n",
    "\n",
    "def train_test_split(df: pd.DataFrame, k: int) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''Split a dataframe into train and test.'''\n",
    "    begin, end = (k * len(df) // K_FOLDS), ((k+1) * len(df) // K_FOLDS)\n",
    "    output_df = df.iloc[begin:end]\n",
    "    input_df = df.drop(output_df.index)\n",
    "    return input_df, output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35125f1-f356-48bc-b643-67be15cd904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization functions\n",
    "def visualize_distances(distances: list[np.ndarray], names: list[str]) -> None:\n",
    "    '''Visualize the distances found through the resampling calculation.'''\n",
    "    ax, fig = plt.subplots()\n",
    "    for i, distance in enumerate(distances):\n",
    "        plt.plot(distance, alpha=0.4, label=names[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7042791-5879-4bdc-b44f-77a0b419cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primary distance functions\n",
    "def normal_resample(inputs: np.ndarray, classes: np.ndarray, needed_classes: np.ndarray, method_name: str) -> np.ndarray:\n",
    "    '''Resample with one of the traditional geometric methods.'''\n",
    "    original = collections.Counter(classes)\n",
    "    needed = collections.Counter(needed_classes)\n",
    "    for key in original:\n",
    "        needed[key] = original[key] if key not in needed else original[key] + needed[key]\n",
    "    method = resampling_methods[method_name](sampling_strategy=needed)\n",
    "    input_length = len(inputs)\n",
    "    inputs, classes = method.fit_resample(inputs, classes)\n",
    "    return inputs[input_length:]\n",
    "\n",
    "def aug_resample(split: int, needed_classes: np.ndarray, \n",
    "                 rep_func: typing.Callable, rep_list: typing.Union[list[str], dict[str, float]]) -> np.ndarray:\n",
    "    '''Perform augmented resampling.'''\n",
    "    aug_df = pd.read_csv(AUG_NAME)\n",
    "    begin, end = (split * len(aug_df) // K_FOLDS), ((split+1) * len(aug_df) // K_FOLDS)\n",
    "    aug_df = aug_df.drop(aug_df.iloc[begin:end].index)\n",
    "    needed_counter = collections.Counter(needed_classes)\n",
    "    to_return = []\n",
    "    for i in sorted(list(set(needed_classes))):\n",
    "        temp_df = aug_df[aug_df['type'] == i]\n",
    "        to_return += temp_df.sample(needed_counter[i])[INPUT_NAME].tolist()\n",
    "    return np.array([np.array(rep_func(item, rep_list)) for item in to_return])\n",
    "\n",
    "def resample(inputs: np.ndarray, classes: np.ndarray, needed_classes: np.ndarray, \n",
    "             method_name: str, split: int, rep_func: typing.Callable, \n",
    "             rep_list: typing.Union[list[str], dict[str, float]]) -> np.ndarray:\n",
    "    '''Resample given inputs.'''\n",
    "    return aug_resample(split, needed_classes, \n",
    "                        rep_func, rep_list) if method_name == 'aug' else normal_resample(inputs, classes, \n",
    "                                                                                needed_classes, method_name)\n",
    "\n",
    "def k_fold_loop(df: pd.DataFrame, rep_func: typing.Callable, method_name: str, \n",
    "                rep_list: typing.Union[list[str], dict[str, float]], output_name: str) -> np.ndarray:\n",
    "    '''Loop through each fold in k-fold cross validation to find result.'''\n",
    "    all_arrays = []\n",
    "    for i in range(K_FOLDS):\n",
    "        input_df, output_df = train_test_split(df, i)\n",
    "        input_arr, output_arr = represent_text(input_df, rep_func, rep_list), represent_text(output_df, rep_func, rep_list)\n",
    "        input_class, output_class = input_df[output_name].to_numpy(), output_df[output_name].to_numpy()\n",
    "        resampled = resample(input_arr, input_class, output_class, method_name, i, rep_func, rep_list)\n",
    "        output_arr = np.array([item[1] for item in sorted(zip(output_class.tolist(), output_arr.tolist()))]) #correct order\n",
    "        distances = find_distances(output_arr, resampled)\n",
    "        all_arrays.append(distances)\n",
    "    return np.concatenate(all_arrays)\n",
    "\n",
    "def get_resampling_dist(df: pd.DataFrame, method_name: str, output_name: str) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    '''Loop through each rep method given an input and output df as well as a method name and find results.'''\n",
    "    wordlist, frequency_counter = get_wordlist(df)\n",
    "    word_dict = get_worddict(df, frequency_counter, wordlist)\n",
    "    rep_methods = [{'name': 'bow', 'function': bow, 'wordlist': wordlist}, #methods for representing text\n",
    "                   {'name': 'freq', 'function': freq, 'wordlist': wordlist},\n",
    "                   {'name': 'tfidf', 'function': tfidf, 'wordlist': word_dict},]\n",
    "    \n",
    "    distance_list = []\n",
    "    for rep_method in rep_methods:\n",
    "        rep_name, rep_func, rep_list = rep_method['name'], rep_method['function'], rep_method['wordlist']\n",
    "        distances = k_fold_loop(df, rep_func, method_name, rep_list, output_name)\n",
    "        distance_list.append(distances)\n",
    "    return tuple(distance_list)\n",
    "\n",
    "def evaluate_methods(filename: str, input_name: str, output_names: list[str]) -> None:\n",
    "    '''Evaluate all methods for a file.'''\n",
    "    df = pd.read_csv(filename)\n",
    "    df[INPUT_NAME] = df[input_name].astype(str) #ensure i/o columns all have the same names\n",
    "    df = combine_answers(df, output_names)\n",
    "    for (i, incorrect_output_name) in enumerate(output_names):\n",
    "        df[OUTPUT_NAMES[i]] = df[incorrect_output_name]\n",
    "    df = df[df[OUTPUT_NAMES[1]] != 1]\n",
    "    \n",
    "    for resampling_method in resampling_methods:\n",
    "        bow_dist, freq_dist, tfidf_dist = get_resampling_dist(df, resampling_method, OUTPUT_NAMES[1])\n",
    "        print(resampling_method)\n",
    "        print(f'\\tmean: {np.mean(bow_dist):.3f}, {np.mean(freq_dist):.3f}, {np.mean(tfidf_dist):.3f}')\n",
    "        print(f'\\tmedian: {np.median(bow_dist):.3f}, {np.median(freq_dist):.3f}, {np.median(tfidf_dist):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516979cd-dab1-4609-902e-9154685be98a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE\n",
      "\tmean: 3.521, 0.164, 0.278\n",
      "\tmedian: 3.606, 0.152, 0.260\n",
      "RandomOver\n",
      "\tmean: 3.811, 0.186, 0.291\n",
      "\tmedian: 3.873, 0.172, 0.271\n",
      "aug\n",
      "\tmean: 3.786, 0.191, 0.310\n",
      "\tmedian: 3.742, 0.182, 0.297\n"
     ]
    }
   ],
   "source": [
    "evaluate_methods('../data/antisemitism_dataset.csv', INPUT_NAME, ['classification', 'type_of_antisemitism'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
